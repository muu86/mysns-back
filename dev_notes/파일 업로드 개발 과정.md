# 파일 업로드 개발 과정

파일 업로드 처리에 관한 좌충우돌 해결 과정을 기록한다.

- [파일 업로드 개발 과정](#파일-업로드-개발-과정)
  - [기존 - Spring에서 처리](#기존---spring에서-처리)
  - [클라이언트에서 바로 s3 로 파일 전송](#클라이언트에서-바로-s3-로-파일-전송)
    - [CDK](#cdk)
    - [Lambda Layer](#lambda-layer)
    - [Lambda 메모리 설정](#lambda-메모리-설정)
  - [포스트맨 테스트](#포스트맨-테스트)
  - [CORS](#cors)
  - [클라이언트 컴포넌트에서 API 요청하기](#클라이언트-컴포넌트에서-api-요청하기)
  - [Lambda 로 파일 업로드 시 사이즈 제한 문제](#lambda-로-파일-업로드-시-사이즈-제한-문제)
  - [Presigned Url 을 클라이언트에게 제공](#presigned-url-을-클라이언트에게-제공)
  - [S3 Event 를 Lambda 로 처리할 때 무한루프를 주의해야 한다](#s3-event-를-lambda-로-처리할-때-무한루프를-주의해야-한다)
    - [Event Filter 로 해결](#event-filter-로-해결)
  - [스프링 서버 File Manager](#스프링-서버-file-manager)
    - [presignGetObject 메서드를 반복문에서 사용해도 문제없는가](#presigngetobject-메서드를-반복문에서-사용해도-문제없는가)


## 기존 - Spring에서 처리

File 처리용 `FileService` 가 `FileRepository`를 참조하도록 하고, Aws S3 용 Repository인 `S3FileRepository` 를 구현했다.

사용자가 mulipart 타입으로 파일을 전송하면 스프링에서 파일을 aws에 전송할 수 있다. `Image4j` 라이브러리를 사용하면 java 에서도 이미지 전처리가 가능하다.

```java
@Component
public class S3FileRepository implements FileRepository {


    private final S3Client s3;

    private final S3Presigner presigner;

    @Override
    public Optional<FileLocation> saveFile(MultipartFile file) {

//        String originalFilename = file.getOriginalFilename();
        String objectKey = UUID.randomUUID().toString();

        try {
            PutObjectResponse putObjectResponse = s3.putObject(request -> request
                    .bucket(BUCKET_NAME)
                    .key(objectKey)
                    .contentType(file.getContentType())
                    .contentLength(file.getSize())
//                    .metadata(Map.of("Original-Filename", originalFilename))
                ,
                RequestBody.fromByteBuffer(ByteBuffer.wrap(file.getBytes())));

            if (putObjectResponse == null || !putObjectResponse.sdkHttpResponse().isSuccessful()) {
                return Optional.empty();
            }

        } catch (IOException e) {
            return Optional.empty();
        }

        return Optional.of(new FileLocation(objectKey, FileLocationType.S3));

    }

    // ...
}
```

## 클라이언트에서 바로 s3 로 파일 전송

원본 사진 파일은 용량이 꽤 커서 테스트하면서 여러장을 업로드 할 경우 10mb 이상을 업로드 하는 경우도 종종 생겼다. 사용자 -> Nextjs -> Spring -> S3 를 거치게되면 효율적이지 않은 것 같아서 Spring 에서 이미지를 처리하지 않고 사용자 클라이언트가 바로 S3 로 업로드하는 것으로 변경해보기로 했다. `ApiGateway`에 `Lambda` 핸들러를 설정했다. `sharp` 라이브러리를 사용하여 원본 이미지를 가로 1080px, 400px, 200px 로 리사이징해서 s3 에 저장한다.

```ts
import { APIGatewayProxyEvent } from 'aws-lambda';
import sharp from 'sharp';
import { randomUUID } from 'crypto';
import { PutObjectCommand, S3Client } from '@aws-sdk/client-s3';

export const handler = async (event: APIGatewayProxyEvent) => {
  const imageBuffer = Buffer.from(event.body!, 'base64');
  const resize = [1080, 400, 200];
  const promises = resize.map((r) => sharp(imageBuffer).resize({ width: r }).withMetadata().toBuffer());
  const resized = await Promise.all(promises);
  const buffers = [imageBuffer, ...resized];

  const s3Client = new S3Client();

  const resizeTag = ['', '_1080', '_400', '_200'];
  const key = randomUUID();
  console.log('key: ', key);
  const buffersPromise = buffers.map((b, i) => {
    return s3Client.send(
      new PutObjectCommand({
        Bucket: process.env.BUCKET_NAME,
        Key: `${key}${resizeTag[i]}`,
        Body: b,
      })
    );
  });
  const result = await Promise.all(buffersPromise);
  console.log(result);

  try {
    return {
      statusCode: 200,
      body: JSON.stringify({
        message: 'success',
        key: key,
      }),
    };
  } catch (err) {
    console.log(err);
    return {
      statusCode: 500,
      body: JSON.stringify({
        message: 'some error happened',
      }),
    };
  }
};
```

### CDK

cdk 를 통해 리소스를 구성했다. cdk 는 코드를 통해서 AWS 리소스를 관리할 수 있게 도와주는 툴이다. cdk 는 클라우드 포메이션 yaml 파일을 코드로 생성하도록 도와준다. 클라우드 포메이션의 장점은 프로젝트 별로 사용 중인 리소스를 관리할 수 있다는 것이다. AWS를 사용하다 보면 사용 중인 리소스가 어떤 프로젝트에 연결된 것인지 헷갈리는 일이 생긴다. 또한, 프로젝트는 종료했는데 리소스는 여전히 켜져있어서 요금이 야금야금 나가는 일도 있기 때문에 클라우드 포메이션이 유용하다. 그런데 클라우드 포메이션은 yaml 이나 json 으로 리소스를 관리하는 툴인데 cdk 는 이를 프로그래밍 언어로 관리하도록 도와준다.

AWS 에 빠싹하다면 콘솔보다 cdk 가 분명히 훨씬 편하겠지만 익숙하지 않은 단계에서 cdk를 사용하는 건 쉽지 않다. 관련 자료도 aws 에서 제공하는 깃허브 샘플코드 정도가 다다. 그래도 습관을 들여놓으면 좋을 것 같아서 사용해려고 노력 중이다.

### Lambda Layer

`Lambda`는 간단한 함수를 정의해 놓고 필요할 때만 AWS 리소스를 사용해서 함수를 실행할 수 있게 해준다. 함수를 zip 파일이나 docker image 로 만들어서 저장해놓고 필요할 때 aws 가 이를 실행한다. 그런데 함수가 의존하는 모듈이 있으면 부팅시간이 느려질 수 있다.

`Lambda Layer` 를 이용해서 의존성을 미리 따로 빼놓을 수가 있다. Lamdba Layer 에 설치된 모듈이 Lambda 실행환경에서 node_modules 로 붙는다. 나는 `sharp` 라이브러리를 Lambda Layer 로 빼놓았다.

```ts
import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';
import * as s3 from 'aws-cdk-lib/aws-s3';
import * as lambda from 'aws-cdk-lib/aws-lambda';
import { NodejsFunction } from 'aws-cdk-lib/aws-lambda-nodejs';
import * as apigw from 'aws-cdk-lib/aws-apigateway';

export class CdkStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    const bucket = new s3.Bucket(this, 'MySns', {
      bucketName: 'my-sns',
      versioned: true,
      removalPolicy: cdk.RemovalPolicy.DESTROY,
      autoDeleteObjects: true,
    });

    const api = new apigw.RestApi(this, 'MySnsApi', {
      restApiName: 'my-sns-api',
      binaryMediaTypes: ['image/*'],
    });

    const files = api.root.addResource('files');
    const file = files.addResource('{id}');

    const layer = new lambda.LayerVersion(this, 'ImageProcessingLayer', {
      code: lambda.Code.fromAsset('resources/lambda-layer/image-processing-layer'),
      compatibleRuntimes: [lambda.Runtime.NODEJS_20_X],
      compatibleArchitectures: [cdk.aws_lambda.Architecture.ARM_64],
      removalPolicy: cdk.RemovalPolicy.DESTROY,
    });

    const fileHandler = new NodejsFunction(this, 'file-handler', {
      functionName: 'file-handler-v2',
      runtime: lambda.Runtime.NODEJS_20_X,
      architecture: cdk.aws_lambda.Architecture.ARM_64,
      entry: './resources/lambda/file-handler.ts',
      handler: 'handler',
      layers: [layer],
      bundling: {
        externalModules: ['sharp'],
      },
      environment: {
        BUCKET_NAME: bucket.bucketName,
      },
      timeout: cdk.Duration.seconds(15),
      memorySize: 512,
    });

    bucket.grantReadWrite(fileHandler);

    files.addMethod('POST', new apigw.LambdaIntegration(fileHandler));
  }
}
```

### Lambda 메모리 설정

aws를 사용하면서 몇 번 데여본 적이 있어서 요금에 민감하다. 얼마전엔 RDB Aurora serverless 가 사용한 시간만큼만 요금을 지불하면 된다고 소개를 하길래 순진하게 믿고 그냥 켜두었다가 이틀만에 2만원이 나갔다...

Lambda 는 메모리별로 사용한 시간에 따라 요금이 책정된다. Lambda 런타임 시 사용할 메모리 양을 설정할 수 있다. 기본 메모리는 128mb 인데 sharp 사용 시 메모리 부족으로 에러가 나서 메모리를 늘려야했다. 메모리 할당을 늘려가면서 이미지 처리 시간은 얼마나 걸리는지, 요금은 어떻게 변하는지 테스트해봤다. cpu 는 x64, arm64 중에 arm 이 조금 더 싸기 때문에 arm을 사용했다.

`람다 요금(arm)`

```
메모리(MB)	1밀리초당 요금
128	    0.0000000017 USD
512	    0.0000000067 USD
1,024	0.0000000133 USD
1,536	0.0000000200 USD
```

`1mb 이미지 처리에 걸린 시간`

```
메모리(MB)	초                      요금
128	      메모리부족 -> 에러        x
512	      4353ms                0.0000291651
1,024     2551ms                0.0000339283
1,536	  1561ms                0.00003122
```

1536mb 메모리를 사용할 때 처리시간도 빨라지고 요금도 크게 차이가 없어서 1536mb 메모리를 사용했다.`sharp` 매뉴얼에서도 aws lambda 사용 시 1536mb 를 예로 들고 있긴 했는데 가장 효율적인 것 같다.

## 포스트맨 테스트

<img width=400 src="images/스크린샷 2024-04-10 오전 2.09.49.png">
<img width=800 src="images/스크린샷 2024-04-10 오전 2.07.31.png">

포스트맨으로 파일 전송 시 이미지 파일을 리사이징에서 s3에 저장한 것을 확인했다. Lambda가 s3 key를 리턴해줬기 때문에 스프링으로 전송 후 디비에 저장하면 될 것 같다.

## CORS

프론트에서 바로 ApiGateway 에 요청을 날리면 CORS 에러가 난다. 브라우저는 기본적으로 자바스크립트를 이용해서 현재 사이트가 아닌 다른 자원에 요청을 날리는 것을 제한한다. 클라이언트에서 바로 API 요청을 날리기 위해선 ApiGateway와 Lambda에서 CORS 를 활성화시켜야 한다.

```ts
// cdk-stack.ts
const api = new apigw.RestApi(this, 'MySnsApi', {
  restApiName: 'my-sns-api',
  binaryMediaTypes: ['application/octet-stream', 'image/*'],
});

const files = api.root.addResource('files');

files.addMethod('POST', new apigw.LambdaIntegration(fileHandler));
files.addCorsPreflight({
  allowOrigins: ['*'],
  allowMethods: ['POST'],
  allowHeaders: ['Content-Type'],
});
```

```ts
// lambda
return {
  statusCode: 200,
  headers: {
    'Access-Control-Allow-Headers': 'Content-Type,X-Api-Key',
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'OPTIONS,POST',
  },
  body: JSON.stringify({
    message: 'success',
    key: key,
  }),
};
```

프론트를 배포하고 난 뒤에는 origin을 프론트 도메인으로 설정해야 할 것이다.

Lambda 와 ApiGateway 를 통합 프록시로 사용하는 경우에는 두 군데 모두 CORS 를 활성화 시키는 설정이 필요하다. ApiGateway에서는 `addCorsPreflight` 메서드를 이용했고, Lambda에서는 응답 헤더에 설정을 추가한다.

## 클라이언트 컴포넌트에서 API 요청하기

사용자가 `input` 태그로 파일을 업로드하면 Change Event 핸들러에서 파일을 업로드한다. 업로드가 완료되고 s3 key를 반환받으면 ImageFile 객체에 일단 저장해둔다. 나중에 사용자가 submit 버튼을 눌렀을 때 s3 key를 백엔드에 전송한다.

```tsx
// create-post-form.tsx
type ImageFile = {
  url: string;
  file: File;
  s3Key?: string;
};

export default function CreatePostForm() {
  const [imageFiles, setImageFiles] = useState<ImageFile[]>([]);

  const handleFileInput = async (event: ChangeEvent<HTMLInputElement>) => {
    event.preventDefault();
    const file = event.target.files?.[0];
    if (file) {
      //...

      const key = await uploadFile(file);
      if (!key) console.log('파일 upload 실패');
      else newFile.s3Key = key;
    }
  };
```

```tsx
// utils.ts
export async function uploadFile(file: File): Promise<string | null> {
  const buffer = await file.arrayBuffer();

  const response = await fetch(`${process.env.NEXT_PUBLIC_FILE_UPLOAD_URL}`, {
    method: 'POST',
    body: buffer,
    headers: {
      'Content-Type': file.type,
    },
  });

  if (response.status !== 200) {
    console.log(response.body);
    return null;
  }

  const result = await response.json();
  console.log('uploadfile: ', result);
  return result.key;
}
```

사진 업로드 후 응답을 받기까지 1~2 초의 시간이 걸리는데 이 틈에 사용자가 저장 버튼을 누르게 되면 아직 s3 key 를 받지 못한 상태에서 form submit 이 실행된다. uploading 상태를 등록해서 s3 key 를 받아오는 동안은 등록버튼을 누를 수 없게 했다.

```tsx
{
  states.uploading ? (
    <div className="w-8 h-8 flex items-center justify-center">
      <Spinner h={8} />
    </div>
  ) : (
    <button className="w-8 h-8 flex items-center justify-center" onClick={submitButtonHandler}>
      <CheckCircleIcon className="w-10 h-10 self-center" />
    </button>
  );
}
```

## Lambda 로 파일 업로드 시 사이즈 제한 문제

Lambda의 요청, 응답 페이로드는 6mb 제한이 있다. 원본 사진을 업로드하면서 알게 됐다. nextjs 에서 이미지를 리사이징 후 s3 에 업로드하는 방법도 생각해봤지만 원본 파일을 버려야 하기 때문에 고민이 됐다.

https://stackoverflow.com/questions/54528768/handling-multipart-form-data-on-api-gateway-lambda

Lambda 로 이미지를 업로드하는 방법보다 클라이언트가 s3 로 직접 파일을 업로드한 뒤에 s3 이벤트를 처리하는 Lambda를 두는게 더 일반적인 방법이라는 것을 배웠다. s3 이벤트를 처리하는 Lambda 에 대한 용량 제한은 없다. 그리고 클라이언트에게 s3 를 안전하게 노출하기 위해서 `presigned url` 을 사용해야 한다. 클라이언트에게 s3 object 를 넘겨줄 때만 presigned url이 있는 줄 알았는데 `put object` 시에도 presigned url을 제공할 수 있다는 것은 처음 알았다.

## Presigned Url 을 클라이언트에게 제공

s3 는 기본적으로 public access 를 제한하는데 일정 시간 동안 유효한 presigned url을 클라이언트에게 제공할 수 있다.

```ts
// 클라이언트 코드
export async function getPresignedUrl() {
  const param = {
    key: randomUUID(),
  };
  const response = await fetch(`${process.env.FILE_UPLOAD_URL}/presigned?${stringify(param)}`);
  const result = await response.json();
  return result.url;
}
```

sdk 의 getSignedUrl 을 사용해서 s3 오브젝트에 대한 presigned url 을 받아오고 리턴한다.

```ts
// lambda
import { PutObjectCommand, S3Client } from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
import { APIGatewayProxyEvent } from 'aws-lambda';

export const handler = async (event: APIGatewayProxyEvent) => {
  try {
    if (!event.queryStringParameters || !event.queryStringParameters['key']) {
      throw new Error('key 파라미터가 null 입니다.');
    }
    const key = event.queryStringParameters['key'];
    const s3 = new S3Client({});
    const command = new PutObjectCommand({
      Bucket: process.env.BUCKET_NAME,
      Key: `${key}`,
    });
    const url = await getSignedUrl(s3, command, { expiresIn: 60 });

    return {
      statusCode: 200,
      body: JSON.stringify({
        url: url,
      }),
    };
  } catch (err) {
    console.log(err);
    return {
      statusCode: 500,
      body: JSON.stringify({
        message: err.message,
      }),
    };
  }
};
```

리액트 클라이언트 컴포넌트에서 s3 로 직접 파일을 업로드한다.

```ts
const handleFileInput = async (event: ChangeEvent<HTMLInputElement>) => {
  event.preventDefault();
  const file = event.target.files?.[0];
  if (file) {
    //...
    const buffer = await file.arrayBuffer();
    const presignedUrl = await getPresignedUrl();
    const response = await fetch(presignedUrl, {
      method: 'PUT',
      body: buffer,
    });
  }
};
```

## S3 Event 를 Lambda 로 처리할 때 무한루프를 주의해야 한다

https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/with-s3-tutorial.html

aws 매뉴얼에서도 소개하는 예제인데 내 멋대로 구현하다가 주의할 점이 있어서 기록한다. aws 매뉴얼에선 분명히 버켓을 두개를 만들라고 하는데 나는 하나로 하다가 문제가 생겼다.

```ts
// lambda 정의
const resizeFileHandler = new NodejsFunction(this, 'resize-file-handler', {
  functionName: 'resize-file-handler',
  runtime: lambda.Runtime.NODEJS_20_X,
  architecture: cdk.aws_lambda.Architecture.ARM_64,
  entry: './resources/lambda/resize-file-handler.ts',
  handler: 'handler',
  layers: [layer],
  bundling: {
    externalModules: ['sharp'],
  },
  memorySize: 1536,
});
// s3 put 이벤트에 lambda 등록
const s3PutEventSource = new lambdaEventSources.S3EventSource(bucket, {
  events: [s3.EventType.OBJECT_CREATED_PUT],
});
resizeFileHandler.addEventSource(s3PutEventSource);
```

```ts
// lambda 코드
export const handler = async (event: S3Event) => {
  try {
    const bucketName = event.Records[0].s3.bucket.name;
    const key = event.Records[0].s3.object.key;

    const s3 = new S3Client({});
    const getCommand = new GetObjectCommand({
      Bucket: bucketName,
      Key: key,
    });
    // ...

    const buffersPromise = resized.map((b, i) => {
      const putCommand = new PutObjectCommand({
        Bucket: bucketName,
        Key: `${resize[i]}/${key}`,
        Body: b,
      });
      return s3.send(putCommand);
    });
    const result = await Promise.all(buffersPromise);
```

- 클라이언트가 S3 로 파일을 업로드
- s3 이벤트가 발동
- Lambda 핸들러가 이미지를 처리
- 처리된 이미지 S3에 저장
- 다시 s3 이벤트 발동
- 무한루프

`GetObjectCommand` 로 업로드된 파일을 받아온 뒤 리사이즈한 뒤 같은 버킷에 `PutObjectCommand` 로 처리된 이미지를 업로드했다. 같은 버킷에 또 CreateObject 이벤트가 발생하기 때문에 Lambda는 자기가 업로드한 파일때문에 무한루프에 빠지게 된다.

aws 매뉴얼에서는 버킷을 두개 만들어서 resize 용 버킷을 따로 설정했는데 무시하고 버킷 하나로 작업하다가 깜짝 놀랄 일이 벌어지고 말았다...Lambda가 10분정도 계속 돌아가고 있었고 강제로 종료할 방법이 없어서 헤매다가 10분 정도가 추가로 더 돌아간 것 같다.

https://docs.aws.amazon.com/ko_kr/lambda/latest/operatorguide/recursive-runaway.html

나중에 알아보니 검색해보니 aws 에서도 이를 해결하는 방법을 소개하고 있다. 나는 당황해서 s3 버킷 자체를 수동으로 삭제해서 무한루프를 종료할 수 있었다. 작업을 하면서 이렇게 하면 람다가 무한루프에 빠지지 않을까 의심했기 때문에 `cloud watch`를 확인했다. 그나마 빨리 발견할 수 있어서 다행이었다.

### Event Filter 로 해결

https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/notification-how-to-filtering.html

```ts
const s3PutEventSource = new lambdaEventSources.S3EventSource(bucket, {
  events: [s3.EventType.OBJECT_CREATED_PUT],
  filters: [{ prefix: 'raw/' }],
});
```

s3 event 에 filter 를 적용할 수 있다. 클라이언트는 이미지 원본을 `raw/` prefix 에 업로드하고 해당 prefix 에만 이벤트가 발동하도록 설정했다.

Lambda 는 리사이징된 이미지를 각각의 prefix에 저장하므로 raw/ prefix 에 설정된 이벤트는 발동하지 않는다.

```ts
export class CdkStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    const bucket = new s3.Bucket(this, 'MySns', {
      bucketName: 'my-sns',
      versioned: true,
      removalPolicy: cdk.RemovalPolicy.DESTROY,
      autoDeleteObjects: true,
      cors: [
        {
          allowedMethods: [s3.HttpMethods.GET, s3.HttpMethods.PUT],
          allowedOrigins: ['*'],
        },
      ],
    });

    const api = new apigw.RestApi(this, 'MySnsApi', {
      restApiName: 'my-sns-api',
      binaryMediaTypes: ['application/octet-stream', 'image/*'],
    });

    const layer = new lambda.LayerVersion(this, 'ImageProcessingLayer', {
      code: lambda.Code.fromAsset('resources/lambda-layer/image-processing-layer'),
      compatibleRuntimes: [lambda.Runtime.NODEJS_20_X],
      compatibleArchitectures: [cdk.aws_lambda.Architecture.ARM_64],
      removalPolicy: cdk.RemovalPolicy.DESTROY,
    });

    const presignedUrlHandler = new NodejsFunction(this, 'PresignedUrlHandler', {
      functionName: 'presigned-url-handler',
      runtime: lambda.Runtime.NODEJS_20_X,
      architecture: cdk.aws_lambda.Architecture.ARM_64,
      entry: './resources/lambda/presigned-url-handler.ts',
      handler: 'handler',
      environment: {
        BUCKET_NAME: bucket.bucketName,
      },
    });

    const resizeFileHandler = new NodejsFunction(this, 'ResizeFileHandler', {
      functionName: 'resize-file-handler',
      runtime: lambda.Runtime.NODEJS_20_X,
      architecture: cdk.aws_lambda.Architecture.ARM_64,
      entry: './resources/lambda/resize-file-handler.ts',
      handler: 'handler',
      layers: [layer],
      bundling: {
        externalModules: ['sharp'],
      },
      timeout: cdk.Duration.seconds(10),
      memorySize: 1536,
    });
    const s3PutEventSource = new lambdaEventSources.S3EventSource(bucket, {
      events: [s3.EventType.OBJECT_CREATED_PUT],
      filters: [{ prefix: 'raw/' }],
    });
    resizeFileHandler.addEventSource(s3PutEventSource);

    bucket.grantReadWrite(presignedUrlHandler);
    bucket.grantReadWrite(resizeFileHandler);

    api.root.addResource('presigned').addMethod('GET', new apigw.LambdaIntegration(presignedUrlHandler));
  }
}
```

```ts
const prefix = ['lg', 'md', 'sm'];
const buffersPromise = resized.map((b, i) => {
  const putCommand = new PutObjectCommand({
    Bucket: bucketName,
    Key: `${prefix[i]}/${key.split('/')[1]}`,
    Body: b,
  });
  return s3.send(putCommand);
});
const result = await Promise.all(buffersPromise);
```



## 스프링 서버 File Manager

getPost 요청이나 getUserProfile 요청 등에 파일 정보도 항상 포함된다. `File Manager` 서비스를 추가해서 디비에 저장된 s3 object key를 실제 url 로 변환하는 역할을 담당하게 했다. 기존에는 Controller 에서 Multipart 로 파일을 받은 뒤에 File Manager 가 s3에 Put 하는 역할까지 담당했었는데 이제 파일 업로드는 필요가 없어졌다. 파일을 요청할 때만 presigned url을 제공해주면 된다.

```java
  @Override
    public FileUrl getFileUrl(FileLocation location) {
        String[] suffix = { "raw/%s", "lg/%s", "md/%s", "sm/%s" };

        FileUrl fileUrl = FileUrl.builder()
            .raw(getPresignedGetObjectRequest(suffix[0].formatted(location.getKey())).url()
                .toString())
            .lg(getPresignedGetObjectRequest(suffix[1].formatted(location.getKey())).url()
                .toString())
            .md(getPresignedGetObjectRequest(suffix[2].formatted(location.getKey())).url()
                .toString())
            .sm(getPresignedGetObjectRequest(suffix[3].formatted(location.getKey())).url()
                .toString())
            .build();

        return fileUrl;
    }

    private PresignedGetObjectRequest getPresignedGetObjectRequest(String key) {
        return presigner.presignGetObject(
            builder -> builder
                .signatureDuration(Duration.ofMinutes(5))
                .getObjectRequest(request -> request
                    .bucket(BUCKET_NAME)
                    .key(key)
                    .build())
                .build());
    }
```

### presignGetObject 메서드를 반복문에서 사용해도 문제없는가

https://stackoverflow.com/questions/70712240/retrieve-multiple-objects-with-presigned-url-from-s3-python

반복문에서 presigned url 요청을 할 경우 aws 에 한번씩 네트워크 요청이 나가는 줄 알았는데 presigned url 은 aws 에 요청을 날리지는 않는다. 아마 로컬의 aws 인증 정보만을 이용해서 url을 생성하는 것 같다. 파일이 여러개라도 한번씩 presignedGetObject 메서드를 실행해도 문제가 없다.
